{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagdaleyash/phishingdetectiontool/blob/main/Phishing_Email_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa9FXXmNI2gg",
        "outputId": "5670e6da-2e23-42fe-bb87-e11aa6b40ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Total Number of Characters C  Vocabulary richness W/C  Account  Access  \\\n",
            "0                          1673                 0.128512        2       0   \n",
            "1                          4465                 0.137738        0       0   \n",
            "2                          6813                 0.095993        0       0   \n",
            "3                          1518                 0.109354        0       0   \n",
            "4                          1881                 0.126528        7       3   \n",
            "\n",
            "   Bank  Credit  Click  Identity  Inconvenience  Information  ...  Password  \\\n",
            "0     0       0      1         0              0            1  ...         1   \n",
            "1     0       0      0         0              0            4  ...         0   \n",
            "2     0       2      0         0              0            2  ...         0   \n",
            "3     0       1      1         0              0            0  ...         0   \n",
            "4     0       0      0         1              0            2  ...         0   \n",
            "\n",
            "   Recently  Risk  Social  Security  Service  Suspended  \\\n",
            "0         1     0       0         0        0          0   \n",
            "1         0     0       0         3        1          0   \n",
            "2         0     0       0         0        0          0   \n",
            "3         0     0       0         0        0          0   \n",
            "4         0     0       0         0        0          2   \n",
            "\n",
            "   Total number of Function words/W  Unique Words  Phishing Status  \n",
            "0                          0.027907           132                1  \n",
            "1                          0.013008           338                1  \n",
            "2                          0.006116           292                1  \n",
            "3                          0.012048           102                1  \n",
            "4                          0.063025           136                1  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('Phishing_paper1.csv')\n",
        "\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHlsrOgBKy6r",
        "outputId": "79e69f6f-f917-4351-892e-792ffca5891d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-13-3228d249da6e>:11: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('Phishing_paper1.csv', header=None, names=['url', 'label'])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# load the data\n",
        "data = pd.read_csv('Phishing_paper1.csv', header=None, names=['url', 'label'])\n",
        "\n",
        "# drop the first row as it contains column names\n",
        "data = data.drop(data.index[0])\n",
        "\n",
        "# remove rows with missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# convert label column to numeric values\n",
        "data['label'] = pd.to_numeric(data['label'])\n",
        "\n",
        "# replace NaN values with empty strings\n",
        "data['url'].fillna('', inplace=True)\n",
        "\n",
        "# convert url column to string\n",
        "data['url'] = data['url'].astype(str)\n",
        "\n",
        "# define function to clean url\n",
        "def clean_url(url):\n",
        "    url = url.lower()\n",
        "    url = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',url)\n",
        "    url = re.sub(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', 'IPADDRESS', url)\n",
        "    url = re.sub(r'[^\\w\\s]','',url)\n",
        "    url = re.sub(r'\\s+', ' ', url)\n",
        "    return url\n",
        "\n",
        "data['url'] = data['url'].apply(clean_url)\n",
        "\n",
        "# tokenize the urls\n",
        "def tokenize_url(url):\n",
        "    tokens = word_tokenize(url)\n",
        "    return tokens\n",
        "\n",
        "data['tokens'] = data['url'].apply(tokenize_url)\n",
        "\n",
        "# remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stop_words(tokens):\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "data['tokens'] = data['tokens'].apply(remove_stop_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDQpw_2LohPI",
        "outputId": "898aabcb-3e63-45d9-af1e-265faf805d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorized URLs shape: (525754, 2121)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# create CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# join the tokens into a single string\n",
        "data['tokens'] = data['tokens'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# fit and transform the tokenized URLs\n",
        "X = vectorizer.fit_transform(data['tokens'])\n",
        "\n",
        "# print the shape of the vectorized URLs\n",
        "print('Vectorized URLs shape:', X.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7obD6rfho5Sp",
        "outputId": "1f706e0d-b316-4fd1-b5aa-b451d81240a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (368027, 2121) (368027,)\n",
            "Testing set shape: (157727, 2121) (157727,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# create training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# print the shape of the training and testing sets\n",
        "print('Training set shape:', X_train.shape, y_train.shape)\n",
        "print('Testing set shape:', X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YHQdpCqo9Ua",
        "outputId": "0601f5db-cb3d-415b-a062-cbd1ea8b709c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9843019901475334\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# create logistic regression model with a high maximum number of iterations\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# fit the model to the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# predict on the testing data\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# calculate accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# print accuracy score\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5fu-TFdvlPg",
        "outputId": "b8bc9430-851a-4c81-cd20-8c859d56ea99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This email is not a phishing email\n"
          ]
        }
      ],
      "source": [
        "# create logistic regression model with a high maximum number of iterations\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# fit the model to the entire preprocessed dataset\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# preprocess the email\n",
        "email = 'http://example.com'\n",
        "\n",
        "email = clean_url(email)\n",
        "tokens = tokenize_url(email)\n",
        "tokens = remove_stop_words(tokens)\n",
        "email = ' '.join(tokens)\n",
        "\n",
        "# vectorize the preprocessed email\n",
        "email_vector = vectorizer.transform([email])\n",
        "\n",
        "# predict whether the email is phishing or not using the trained model\n",
        "prediction = logreg.predict(email_vector)\n",
        "\n",
        "if prediction == 1:\n",
        "    print('This email is a phishing email')\n",
        "else:\n",
        "    print('This email is not a phishing email')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJOvP9uAqvAv",
        "outputId": "93818f9c-87f4-4190-dc9e-fb4841a35e31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    155251\n",
            "           1       0.00      0.00      0.00      2476\n",
            "\n",
            "    accuracy                           0.98    157727\n",
            "   macro avg       0.49      0.50      0.50    157727\n",
            "weighted avg       0.97      0.98      0.98    157727\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# compute classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAaRBHuts2c5",
        "outputId": "2dde9812-9e64-4214-9ae9-87866c3bf161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The email is not a phishing email.\n"
          ]
        }
      ],
      "source": [
        "# example email\n",
        "email = \"Dear customer, we have detected suspicious activity on your account. Please click on the link to verify your account: http://example.com/verify?id=1kjjk23\"\n",
        "\n",
        "# preprocess the email\n",
        "email = clean_url(email)\n",
        "tokens = tokenize_url(email)\n",
        "tokens = remove_stop_words(tokens)\n",
        "email = ' '.join(tokens)\n",
        "\n",
        "# vectorize the email using the trained vectorizer\n",
        "email_vector = vectorizer.transform([email])\n",
        "\n",
        "# predict whether the email is phishing or not using the trained model\n",
        "prediction = logreg.predict(email_vector)\n",
        "\n",
        "if prediction == 1:\n",
        "    print(\"The email is a phishing email.\")\n",
        "else:\n",
        "    print(\"The email is not a phishing email.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1A2YoO2AYek9ixx435bwlPwJHQ72vA9Iw",
      "authorship_tag": "ABX9TyM5u0Lh3LNhb1MNb3mbXoYW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}